<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DORA JAMBOR</title>
    <link>https://dorajam.github.io/thoughts/</link>
    <description>Recent content on DORA JAMBOR</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 23 Sep 2016 18:27:39 +0200</lastBuildDate>
    <atom:link href="https://dorajam.github.io/thoughts/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>An intuition behind eigenvalues</title>
      <link>https://dorajam.github.io/thoughts/post/eigenvalues/</link>
      <pubDate>Fri, 23 Sep 2016 18:27:39 +0200</pubDate>
      
      <guid>https://dorajam.github.io/thoughts/post/eigenvalues/</guid>
      <description>&lt;p&gt;This article aims to give a thorough intuition behind the significance of eigenvectors.&lt;/p&gt;

&lt;p&gt;The first time I got introduced to eigenvectors and eigenvalues, I thought ‘wow this is easy, what’s all the fuss about’. Yet further down the line upon discovering that these concepts are actually used in some very complex systems, I started losing my confidence. There was one question I just could not answer to myself:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why do eigenvalues matter so much? And how can they be applied to such a wide variety of areas?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Generally, I find that there is a huge gap between familiarising oneself with the math of linear algebra and actually developing a visual intuition behind core concepts. Due to the lack of focus on the latter, this aspect of the field only tends to develop over a long course of time. This should not be this way though.&lt;/p&gt;

&lt;p&gt;Recognising this for myself has made me develop quite a strong love for the field. With this post, I will attempt to give you a fun introduction to the significance of eigenvalues and thereby hope you’ll start seeing the bright light at the end of the tunnel of all those dry mathematical derivations.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;An introduction to eigenvectors and eigenvalues&lt;/strong&gt;
And here we begin. You have probably stumbled upon the definition of eigenvalues:
$$
\begin{align}
AV=\lambda v
\end{align}
$$&lt;/p&gt;

&lt;p&gt;Where &lt;code&gt;$v$&lt;/code&gt; is an eigenvector and &lt;code&gt;$\lambda $&lt;/code&gt; is the corresponding eigenvalue. Let’s look at the right side first: You have a vector &lt;code&gt;$v$&lt;/code&gt; that you apply the linear transformation &lt;code&gt;$A$&lt;/code&gt;. On the left: you have the same &lt;code&gt;$v$&lt;/code&gt; vector, but now scaled by some scalar value.&lt;/p&gt;

&lt;p&gt;So you can think of eigenvectors as vectors that do not change their direction after some linear transformation, but merely get scaled by some value. (well, they get reversed if the eigenvalue is negative).&lt;/p&gt;

&lt;p&gt;Now going back to the world of linear transformation, you can think of &lt;code&gt;$A$&lt;/code&gt; as some linear transformation and &lt;code&gt;$v$&lt;/code&gt; as a vector that’s a linear combination of the bases of the space it is defined in (let’s say v = alpha*i + beta*j where alpha and beta are members of the component space). When applying A linear transformation to v, you are actually transforming the whole vector space v was defined in. But hey v was defined in terms of the bases of that space (e.g. i and j), so the bases of the new vector ‘Av&amp;rsquo; will be some new i&amp;rsquo; and j’ basis vectors. This is where it is extremely important that you understand what’s going on visually.&lt;/p&gt;

&lt;p&gt;If you have difficulty internalising this, I &lt;strong&gt;very much&lt;/strong&gt; recommend you read my previous post on &lt;a href=&#34;https://dorajam.github.io/thoughts/post/change-of-basis/&#34;&gt;changing the basis&lt;/a&gt; of some vector space.&lt;/p&gt;

&lt;p&gt;With this in mind, we can think of eigenvectors as vectors that preserve their directions in this new transformed universe. What’s so fascinating about this is that we can transform any vector from the original vector space into this new space just by knowing what the transformation’s eigenpairs are. Doing this will allow us to reduce massive amounts of information that’s needed to reconstruct all points in this new, transformed universe!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What’s more, we can think about eigenvalues in terms of polynomials!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The concept of roots is important as they serve as some fixed ground to a polynomial. Upon finding all roots to a function, we have some notion of the function shape. The same way, we can think of eigenvectors as some components of a vector space that limit the behaviour of a linear transformation.&lt;/p&gt;

&lt;p&gt;Good news, you don’t need to blindly trust me on this one.
Remember equation &lt;code&gt;$(1)$&lt;/code&gt;, we can derive the eigenpairs by finding the null space of the determinant of A - /\I (i.e. det(A-/\I) = 0). If A is R(nxn) then the determinant of the latter term will result in a polynomial of degree n. By the fundamental theorem of algebra, a polynomial of degree n has n (not necessarily unique) complex roots. These are the eigenvalues of A. We can think about these values as &lt;em&gt;”how much should linear transformation A be distorted so that we’ll end up in null space?”&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Why do we care about ending up in null space? Because this is the place where things go extinct. There is no way of reconstructing the previous vector space if all dimensions cease to exist. Think about matrix inversion! You could not flip space back into its original state as you just lost all your information about where you were (with no notation of basis!)&lt;/p&gt;

&lt;p&gt;Fascinating, isn’t it?&lt;/p&gt;

&lt;p&gt;To summarise this point, roughly you could say that the “degree&amp;rdquo; and the orientation of a distortion induced by the transformation can be measured by eigenvalues and eigenvectors, respectively.&lt;/p&gt;

&lt;p&gt;If this wasn’t fascinating enough, allow me to keep going.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Dimensionality Reduction and eigenbases&lt;/strong&gt;
You may have heard that this can all be applied to &lt;strong&gt;dimensionality reduction&lt;/strong&gt;. How so? Well, let’s see.
Eigenvectors are linearly independent. That means, that no eigenvector can be reconstructed by taking a linear combination of another eigenvector: we just simply need them all! This might already make you ponder, would it be possible to switch from using our standard basis vectors to using these powerful eigenvectors that share this special quality? Well it depends.&lt;/p&gt;

&lt;p&gt;There are three scenarios when decomposing eigenvectors:
&lt;strong&gt;(i)&lt;/strong&gt; &lt;em&gt;no eigenvectors exist&lt;/em&gt;
&lt;strong&gt;(ii)&lt;/strong&gt; _the number of eigenvectors is less than the number of dimensions__
&lt;strong&gt;(iii)&lt;/strong&gt; &lt;em&gt;the number of eigenvectors is the same as the number of dimensions&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Change of basis in a vector space</title>
      <link>https://dorajam.github.io/thoughts/post/change-of-basis/</link>
      <pubDate>Tue, 20 Sep 2016 21:53:36 +0200</pubDate>
      
      <guid>https://dorajam.github.io/thoughts/post/change-of-basis/</guid>
      <description>&lt;p&gt;A fascinating characteristic of the human mind is the ability to make connections between different objects and phenomena. The set of mutual beliefs, knowledge and assumptions serves as a common ground enabling us to gain a deeper understanding about our surroundings.&lt;/p&gt;

&lt;p&gt;You can think of units as the words and expressions that define a language. I say ‘apple’ in my language, which you may or may not perceive as the same object depending whether you speak the same language as me.&lt;/p&gt;

&lt;p&gt;To represent different points in space we need some sort of unit of measurement that allows us to speak about things in the same language. Space has no intrinsic grid. Choosing a unit of basis is what will allow us to break space into some imaginary gridlines. Along these grids we can now describe any points in space. Consequently, we can think about our choice of basis as a constructing element or brick that makes up a whole.&lt;/p&gt;

&lt;p&gt;Now imagine a flat world, a two-dimensional universe or plane that’s defined along x and y axes. The conventional way of representing points in 2D space is to use the standard coordinate system, defined by the basis vectors (i) and (j). (Notice, this is just a choice we have collectively made. We could also represent points in 2D using some alternative units of measurement (i.e. along some different set of gridlines)).&lt;/p&gt;

&lt;p&gt;Given our choice, we can now think of a vector as a scaled version of our basis vectors &lt;code&gt;\(i\)&lt;/code&gt; and &lt;code&gt;\(j\)&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;[
  v=\begin{pmatrix}
  3\
  2
 \end{pmatrix}
  *\begin{pmatrix}
  1 &amp;amp; 0 \
  0 &amp;amp; 1
 \end{pmatrix}
]&lt;/p&gt;

&lt;p&gt;As in our standard system we always refer to (i) and (j) as our basis, we can ignore them and just use the following notation:&lt;/p&gt;

&lt;p&gt;$$
  v=\begin{pmatrix}
  3\
  2
 \end{pmatrix}
 $$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Some thoughts on linear transformation&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;When it comes to matrix-vector multiplication, we can think of the matrix in terms of some linear transformation that will redefine the bases of the coordinate system. Applying some transformation (A) to vector (v) from above:&lt;/p&gt;

&lt;p&gt;[
 Av=\begin{pmatrix}
  1 &amp;amp; 2 \
  4 &amp;amp; 3
 \end{pmatrix}*
  \begin{pmatrix}
  3\
  2
 \end{pmatrix}
]&lt;/p&gt;

&lt;p&gt;is actually equivalent to scaling the column vectors of (A) by the entries of (v):&lt;/p&gt;

&lt;p&gt;[
 Av=2\begin{pmatrix}
  1 \
  2
 \end{pmatrix}+
  3\begin{pmatrix}
  4 \
  3
 \end{pmatrix}
]&lt;/p&gt;

&lt;p&gt;Putting this into new light, we can think of this operation as preserving the component space ((v)) of our standard coordinate system, but &lt;em&gt;adjust our units according to the transformation matrix&lt;/em&gt;. As a result, this new vector is just the linear combination of the same components and of a new set of bases.&lt;/p&gt;

&lt;p&gt;But hey, not so fast! As long as we think of the new bases in terms of some scaled version of (i) and (j), we are only speaking in our own language. We merely found a translation of a vector from an alternative universe into our system.&lt;/p&gt;

&lt;p&gt;This is beautifully illustrated by the &lt;a href=&#34;https://www.youtube.com/watch?v=P2LTAUO1TdA&#34;&gt;3Blue1Brown guy&lt;/a&gt; on Youtube.&lt;/p&gt;

&lt;p&gt;The reason I emphasised those imaginary gridlines drawn by our chosen units of basis earlier was to put us into perspective on which system of bases we are referring to. To understand this new vector in terms of your new bases, we would want to think of our bases as the new units of measurement. To do this, let&amp;rsquo;s teleport from thinking of (\begin{pmatrix}1 \ 4\end{pmatrix}) as (\begin{pmatrix}1 \ 0\end{pmatrix}) and of (\begin{pmatrix}2 \ 3\end{pmatrix}) as (\begin{pmatrix}0 \ 1\end{pmatrix}). To carry out this backwards transition we need to apply the inverse of the same operation. This inverse matrix can then be thought of as ‘undoing’ the original transformation, hence serving our goal perfectly.&lt;/p&gt;

&lt;p&gt;I recommend you try to visualise this in your head - or have a look at &lt;a href=&#34;https://www.youtube.com/watch?v=kYB8IZa5AuE&#34;&gt;this&lt;/a&gt;.
With this I hope it becomes clear that a linear transformation is equivalent to stretching, compressing, rotating, flipping our space and thus, adjusting the gridlines that serve as our reference points.&lt;/p&gt;

&lt;p&gt;We are almost there, yay! By now, you may already be pondering about a couple of things…
((i)) &lt;em&gt;How is a point in space represented in one system compared to another?&lt;/em&gt;
((ii)) &lt;em&gt;And how do we understand the same linear transformation in another system?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Let me jump on the first one.&lt;/strong&gt;
I’m going to rely on my favourite 3Blue1Brown guy’s explanation and use Jennifer as the representative of some alternative coordinate system.
As stated earlier, a vector is just a scaled version of its bases. Remember, it really is just the product of a matrix (whose columns are the bases) and a vector whose entries are the components). What we did earlier was preserving the component space, but transforming our system of basis to Jennifer&amp;rsquo;s. Once again, let me clarify, this new system of bases is described in our units /(i/) and /(j/).&lt;/p&gt;

&lt;p&gt;Geometrically this transformation can give us an insight into what Jennifer’s system is like, yet mathematically it is a translation of her world in our world.&lt;/p&gt;

&lt;p&gt;When we referred to the same vector but in two different systems, we in fact ended up talking about two different points in space. So how do we make sure to refer to the same point? Well, we need to apply some different transformation to Jennifer’s basis vectors. This is again where the inverse transformation comes in handy.&lt;/p&gt;

&lt;p&gt;So let’s flip this around, and try to understand a vector from Jennifer’s point of view:&lt;/p&gt;

&lt;p&gt;From my point of view, vector /(v/) in her world is:
[
\begin{pmatrix}
  2 &amp;amp; -1 \
  1 &amp;amp; 1
 \end{pmatrix}i
  \begin{pmatrix}
  3\
  2
 \end{pmatrix}
]
 \boldsymbol{\textsl{Change of basis matrix * Vector in our language = her vector in my language}}&lt;/p&gt;

&lt;p&gt;But for her the same vector is understood as:
\begin{pmatrix}
  2 &amp;amp; -1 \
  1 &amp;amp; 1
 \end{pmatrix}^{-1}i
  \begin{pmatrix}
  3\
  2
 \end{pmatrix}
]&lt;/p&gt;

&lt;p&gt;Consequently, vector /(v/) in her language can be described as follows:
/[
\begin{pmatrix}
  &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt; &amp;amp; &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt; \
  -&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt; &amp;amp; &lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;
 \end{pmatrix}^{-1}i
  \begin{pmatrix}
  3\
  2
 \end{pmatrix}=
\begin{pmatrix}
  &lt;sup&gt;5&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;\
  &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;
 \end{pmatrix}
]
\boldsymbol{\textsl{Inverse change of basis matrix * Vector in my language = vector in her language}}&lt;/p&gt;

&lt;p&gt;With the inverse trick we can translate back and forth from different coordinate systems.&lt;/p&gt;

&lt;p&gt;Tackling the second question&amp;hellip;
Similarly as in 3Blue1Brown, I’m going to demonstrate this by performing a rotation as a transformation. This operation is then denoted by the landing points of rotating both /(i/) and /(j/) in our coordinate system.
[
 M=\begin{pmatrix}
  0 &amp;amp; -1 \
  1 &amp;amp; 0
 \end{pmatrix}
]
You can think about this in terms of some linear transformation to i and j. Even though such operation may be understood as teleporting from one system of bases into another, it is important to notice that the result is still in terms of i and j. Consequently, you should think about A as translating an alternative system’s unit into our language.&lt;/p&gt;

&lt;p&gt;Knowing what transformation it takes to land in this alternative system, we can now think about&lt;/p&gt;

&lt;p&gt;2.) How to understand the same type of transformation in another language?
Similarly as in 3Blue1Brown, I’m going to demonstrate this by performing a 90-degree rotation around the origin. This operation is then denoted by the landing points of rotating both /(i/) and /(j/) in our coordinate system.&lt;/p&gt;

&lt;p&gt;[
 M=\begin{pmatrix}
  0 &amp;amp; -1 \
  1 &amp;amp; 0
 \end{pmatrix}
]&lt;/p&gt;

&lt;p&gt;Notice that applying M directly to an alternative system is not equal to performing the same 90-degree rotation. Why? Think about a stretched out space! Now the angle between the basis vectors may be greater than 90 degrees, resulting in a different point in space than where we intended to land.&lt;/p&gt;

&lt;p&gt;So let’s describe Jennifer’s landing point in her language:
[
\begin{pmatrix}
  0 &amp;amp; -1 \
  1 &amp;amp; 0
 \end{pmatrix}
\begin{pmatrix}
  2 &amp;amp; -1 \
  1 &amp;amp; 1
 \end{pmatrix}v
]&lt;/p&gt;

&lt;p&gt;That is,&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;we first understand where Jennifer’s unit vectors are by scaling our bases (in our language)&lt;/li&gt;
&lt;li&gt;then apply the rotation (in our language)&lt;/li&gt;
&lt;li&gt;finally, translate into her language&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The composition of these three matrices gives us the transformation matrix in Jennifer’s matrix.&lt;/p&gt;

&lt;p&gt;As a final note let’s generalise what happened here. We had some transformation /(M/) described in our coordinate system, which we translated into another coordinate system:
/[A^{-1}MA ]/&lt;/p&gt;

&lt;p&gt;Whenever you see an expression like this, it implies that we have shifted our perspective into an alternative system of coordinates. This will be extremely important for my next post on eigenvalues.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>